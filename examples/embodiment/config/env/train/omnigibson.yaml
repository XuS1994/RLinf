simulator_type: omnigibson
auto_reset: ${algorithm.auto_reset}
ignore_terminations: ${algorithm.ignore_terminations}
use_rel_reward: True
seed: 0
num_group: ${algorithm.num_group_envs}
group_size: ${algorithm.group_size}
use_fixed_reset_state_ids: ${algorithm.use_fixed_reset_state_ids}
max_episode_steps: 80
max_steps: 80
only_eval: False
image_size: [224, 224]

video_cfg:
  save_video: False
  info_on_video: True
  video_base_dir: ${runner.logger.log_path}/video/train

init_params:
  id: "PutCarrotOnPlateInScene-v2"
  num_envs: ${multiply:${algorithm.group_size}, ${algorithm.num_group_envs}}
  obs_mode: "rgb+segmentation"
  control_mode: None
  sim_backend: "gpu"
  sim_config:
    sim_freq: 500
    control_freq: 5
  max_episode_steps: ${env.train.max_episode_steps}
  sensor_configs:
    shader_pack: "default"
  render_mode: all
  task_type: "turning_on_radio"
env_wrapper: 
  _target_: omnigibson.learning.wrappers.RGBLowResWrapper
robot:
  type: R1Pro
  # multi_view_cameras are used by BehaviorIterableDataset
  multi_view_cameras:
    left_wrist: 
      name: robot_r1::robot_r1:left_realsense_link:Camera:0
      resolution: [240, 240]
    right_wrist: 
      name: robot_r1::robot_r1:right_realsense_link:Camera:0
      resolution: [240, 240]
    head: 
      name: robot_r1::robot_r1:zed_link:Camera:0
      resolution: [240, 240]
  # action_keys and action_key_dims are used by the baselines in il_lib repo 
  # You don't need to modify this if you are not training il_lib baselines
  action_keys: [base, torso, left_arm, left_gripper, right_arm, right_gripper]
  action_key_dims:
    base: 3
    torso: 4
    left_arm: 7
    left_gripper: 1
    right_arm: 7
    right_gripper: 1

  # Overwrite below to modify the robot controller 
  controllers: